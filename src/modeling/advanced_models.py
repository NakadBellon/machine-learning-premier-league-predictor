"""
ModÃ¨les avancÃ©s avec les nouvelles features de forme
"""
import pandas as pd
import numpy as np
import logging
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import TimeSeriesSplit
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
import mlflow
import mlflow.sklearn
from datetime import datetime
import os

try:
    from xgboost import XGBClassifier
    XGB_AVAILABLE = True
except ImportError:
    XGB_AVAILABLE = False

try:
    from lightgbm import LGBMClassifier
    LGBM_AVAILABLE = True
except ImportError:
    LGBM_AVAILABLE = False

class AdvancedModelsWithFeatures:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.imputer = SimpleImputer(strategy='median')
        self.scaler = StandardScaler()
        
        self.models = {}
        if XGB_AVAILABLE:
            self.models['xgb'] = XGBClassifier(n_estimators=200, max_depth=6, random_state=42)
        if LGBM_AVAILABLE:
            self.models['lgbm'] = LGBMClassifier(n_estimators=200, max_depth=6, random_state=42, verbose=-1)

    def load_data(self):
        """Charge les donnÃ©es avec features"""
        try:
            processed_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'processed')
            processed_dir = os.path.abspath(processed_dir)
            
            # Chercher le fichier avec features
            files = [f for f in os.listdir(processed_dir)
                    if f.startswith('premier_league_with_features') and f.endswith('.csv')]
            
            if not files:
                raise FileNotFoundError("Aucun fichier avec features trouvÃ©")
                
            latest_file = sorted(files)[-1]
            file_path = os.path.join(processed_dir, latest_file)
            
            self.logger.info(f"Chargement des donnÃ©es avec features: {latest_file}")
            df = pd.read_csv(file_path)
            
            self.logger.info(f"âœ… DonnÃ©es chargÃ©es: {df.shape}")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur chargement donnÃ©es: {e}")
            raise

    def prepare_features_target(self, df):
        """PrÃ©pare les features avancÃ©es"""
        self.logger.info("PrÃ©paration des features avancÃ©es...")
        
        # Toutes les features numÃ©riques sauf les scores rÃ©els
        exclude_features = ['home_score', 'away_score', 'result', 'date', 'season', 
                           'home_team', 'away_team', 'venue', 'referee', 'match_report', 
                           'notes', 'game_id', 'week', 'day', 'time', 'attendance', 'score']
        
        # Features disponibles
        all_features = [col for col in df.columns if col not in exclude_features]
        
        self.logger.info(f"Features utilisÃ©es ({len(all_features)}): {all_features}")
        
        # Conversion numÃ©rique
        for col in all_features:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Nettoyage
        initial_count = len(df)
        df_clean = df.dropna(subset=all_features + ['result'])
        final_count = len(df_clean)
        
        self.logger.info(f"DonnÃ©es aprÃ¨s nettoyage: {final_count}/{initial_count} ({final_count/initial_count*100:.1f}%)")
        
        X = df_clean[all_features]
        y = df_clean['result']
        
        # Imputation et scaling
        X_imputed = self.imputer.fit_transform(X)
        X_scaled = self.scaler.fit_transform(X_imputed)
        
        self.logger.info(f"âœ… Features shape: {X_scaled.shape}")
        self.logger.info(f"ğŸ¯ Target distribution: {y.value_counts().to_dict()}")
        
        return X_scaled, y, df_clean, all_features

    def encode_labels(self, y):
        """Encode les labels textuels en numÃ©riques"""
        label_mapping = {'H': 0, 'D': 1, 'A': 2}
        reverse_mapping = {0: 'H', 1: 'D', 2: 'A'}
        y_encoded = y.map(label_mapping)
        return y_encoded, label_mapping, reverse_mapping

    def decode_predictions(self, y_pred_encoded, reverse_mapping):
        return [reverse_mapping[pred] for pred in y_pred_encoded]

    def train_models(self):
        """EntraÃ®ne les modÃ¨les avec les nouvelles features"""
        self.logger.info("DÃ©but entraÃ®nement avec NOUVELLES FEATURES...")
        
        df = self.load_data()
        X, y, df_clean, feature_names = self.prepare_features_target(df)
        
        # Encodage
        y_encoded, label_mapping, reverse_mapping = self.encode_labels(y)
        
        baseline_accuracy = self.calculate_baseline_accuracy(y_encoded)
        self.logger.info(f"ğŸ“ˆ Accuracy baseline: {baseline_accuracy:.4f}")
        
        tscv = TimeSeriesSplit(n_splits=3)
        results = {}
        
        for model_name, model in self.models.items():
            self.logger.info(f"ğŸ¤– EntraÃ®nement {model_name.upper()}...")
            
            with mlflow.start_run(run_name=f"with_features_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
                fold_accuracies = []
                
                for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
                    X_train, X_test = X[train_idx], X[test_idx]
                    y_train, y_test = y_encoded.iloc[train_idx], y_encoded.iloc[test_idx]
                    
                    model.fit(X_train, y_train)
                    y_pred_encoded = model.predict(X_test)
                    y_pred = self.decode_predictions(y_pred_encoded, reverse_mapping)
                    y_true_decoded = self.decode_predictions(y_test, reverse_mapping)
                    
                    accuracy = accuracy_score(y_true_decoded, y_pred)
                    fold_accuracies.append(accuracy)
                    self.logger.info(f"ğŸ“Š Fold {fold+1} - Accuracy: {accuracy:.4f}")
                
                mean_accuracy = np.mean(fold_accuracies)
                self.logger.info(f"âœ… {model_name} - Accuracy: {mean_accuracy:.4f}")
                self.logger.info(f"ğŸ“ˆ AmÃ©lioration vs baseline: {mean_accuracy - baseline_accuracy:.4f}")
                
                results[model_name] = {
                    'mean_accuracy': mean_accuracy,
                    'baseline_accuracy': baseline_accuracy,
                    'improvement': mean_accuracy - baseline_accuracy
                }
        
        return results

    def calculate_baseline_accuracy(self, y_encoded):
        most_common = y_encoded.value_counts().index[0]
        baseline_pred = [most_common] * len(y_encoded)
        return accuracy_score(y_encoded, baseline_pred)

def main():
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("ğŸš€ TEST AVEC NOUVELLES FEATURES")
        
        project_root = os.path.join(os.path.dirname(__file__), '..', '..')
        mlflow_tracking_uri = "file:///" + os.path.abspath(os.path.join(project_root, "mlruns")).replace("\\", "/")
        mlflow.set_tracking_uri(mlflow_tracking_uri)
        mlflow.set_experiment("Premier_League_With_Features")
        
        advanced_models = AdvancedModelsWithFeatures()
        results = advanced_models.train_models()
        
        if results:
            best_model = max(results.items(), key=lambda x: x[1]['mean_accuracy'])
            best_name, best_result = best_model
            
            logger.info(f"\nğŸ† MEILLEUR MODÃˆLE: {best_name.upper()}")
            logger.info(f"ğŸ¯ Accuracy: {best_result['mean_accuracy']:.4f}")
            logger.info(f"ğŸ’ª AmÃ©lioration vs baseline: +{best_result['improvement']:.4f}")
            
            # Comparaison avec ancien baseline (60.5%)
            improvement_vs_old = best_result['mean_accuracy'] - 0.6051
            logger.info(f"ğŸ“Š vs ancien modÃ¨le (60.5%): {improvement_vs_old:+.4f}")
            
            if improvement_vs_old > 0:
                logger.info("ğŸ‰ MEILLEUR que l'ancien modÃ¨le !")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ ERREUR: {e}")
        raise

if __name__ == "__main__":
    main()